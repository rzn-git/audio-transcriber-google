{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcription saved to output\\1215.txt\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from google.cloud import speech_v1p1beta1 as speech\n",
    "\n",
    "def transcribe_audio_with_diarization(audio_file_path, credentials_path, output_folder):\n",
    "    # Set Google Cloud credentials\n",
    "    os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = credentials_path\n",
    "\n",
    "    # Initialize the client\n",
    "    client = speech.SpeechClient()\n",
    "\n",
    "    # Read the audio file\n",
    "    with open(audio_file_path, \"rb\") as audio_file:\n",
    "        content = audio_file.read()\n",
    "\n",
    "    # Configure recognition request\n",
    "    audio = speech.RecognitionAudio(content=content)\n",
    "    config = speech.RecognitionConfig(\n",
    "        encoding=speech.RecognitionConfig.AudioEncoding.MP3,  # Change to MP3 if your file is MP3\n",
    "        sample_rate_hertz=44100,  # Replace with your audio's sample rate\n",
    "        language_code=\"en-US\",\n",
    "        enable_automatic_punctuation=True,\n",
    "        enable_speaker_diarization=True,\n",
    "        diarization_speaker_count=2,  # Specify the number of speakers\n",
    "        model=\"telephony\"  # Use \"phone_call\" if applicable\n",
    "    )\n",
    "\n",
    "    # Perform the recognition\n",
    "    response = client.recognize(config=config, audio=audio)\n",
    "\n",
    "    # Group words by speakers\n",
    "    speaker_transcripts = {}\n",
    "    for result in response.results:\n",
    "        for word_info in result.alternatives[0].words:\n",
    "            speaker = word_info.speaker_tag\n",
    "            word = word_info.word\n",
    "            if speaker not in speaker_transcripts:\n",
    "                speaker_transcripts[speaker] = []\n",
    "            speaker_transcripts[speaker].append(word)\n",
    "\n",
    "    # Prepare output text\n",
    "    output_text = []\n",
    "    for speaker, words in speaker_transcripts.items():\n",
    "        output_text.append(f\"Speaker {speaker}: {' '.join(words)}\")\n",
    "\n",
    "    # Join the text with line breaks\n",
    "    output_text_str = \"\\n\\n\".join(output_text)\n",
    "\n",
    "    # Ensure the output folder exists\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    # Get the base name of the input audio file without extension\n",
    "    file_name_without_extension = os.path.splitext(os.path.basename(audio_file_path))[0]\n",
    "\n",
    "    # Define the output file path with the same name as the input audio file\n",
    "    output_file_path = os.path.join(output_folder, f\"{file_name_without_extension}.txt\")\n",
    "\n",
    "    # Write to a text file\n",
    "    with open(output_file_path, \"w\", encoding=\"utf-8\") as output_file:\n",
    "        output_file.write(output_text_str)\n",
    "\n",
    "    print(f\"Transcription saved to {output_file_path}\")\n",
    "\n",
    "\n",
    "# Replace with your audio file path, credentials path, and desired output folder\n",
    "audio_file_path = \"dataset/1215.MP3\"  # Change to your file path\n",
    "credentials_path = \"C:/gcloud/service-account-key.json\"  # Change to your credentials file path\n",
    "output_folder = \"output\"  # Specify the output folder\n",
    "\n",
    "# Call the function\n",
    "transcribe_audio_with_diarization(audio_file_path, credentials_path, output_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for the operation to complete...\n",
      "Transcription saved to output\\1217.txt\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from google.cloud import speech_v1p1beta1 as speech\n",
    "\n",
    "def transcribe_audio_with_diarization(audio_file_uri, credentials_path, output_folder):\n",
    "    # Set Google Cloud credentials\n",
    "    os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = credentials_path\n",
    "\n",
    "    # Initialize the client\n",
    "    client = speech.SpeechClient()\n",
    "\n",
    "    # Configure recognition request using the GCS URI\n",
    "    audio = speech.RecognitionAudio(uri=audio_file_uri)  # Use GCS URI here\n",
    "    config = speech.RecognitionConfig(\n",
    "        encoding=speech.RecognitionConfig.AudioEncoding.MP3,  # Adjust for your audio file's encoding\n",
    "        sample_rate_hertz=44100,  # Replace with your audio's sample rate\n",
    "        language_code=\"en-US\",\n",
    "        enable_automatic_punctuation=True,\n",
    "        enable_speaker_diarization=True,\n",
    "        diarization_speaker_count=2,  # Set the number of speakers you expect\n",
    "        model=\"telephony\"  # Use \"phone_call\" or other models as necessary\n",
    "    )\n",
    "\n",
    "    # Use long_running_recognize for longer audio files\n",
    "    operation = client.long_running_recognize(config=config, audio=audio)\n",
    "    \n",
    "    # Wait for the operation to complete\n",
    "    print(\"Waiting for the operation to complete...\")\n",
    "    response = operation.result()\n",
    "\n",
    "    # Group words by speakers\n",
    "    speaker_transcripts = {}\n",
    "    for result in response.results:\n",
    "        for word_info in result.alternatives[0].words:\n",
    "            speaker = word_info.speaker_tag\n",
    "            word = word_info.word\n",
    "            if speaker not in speaker_transcripts:\n",
    "                speaker_transcripts[speaker] = []\n",
    "            speaker_transcripts[speaker].append(word)\n",
    "\n",
    "    # Prepare output text\n",
    "    output_text = []\n",
    "    for speaker, words in speaker_transcripts.items():\n",
    "        output_text.append(f\"Speaker {speaker}: {' '.join(words)}\")\n",
    "\n",
    "    # Join the text with line breaks\n",
    "    output_text_str = \"\\n\\n\".join(output_text)\n",
    "\n",
    "    # Ensure the output folder exists\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    # Get the base name of the input audio file without extension\n",
    "    file_name_without_extension = os.path.splitext(os.path.basename(audio_file_uri))[0]\n",
    "\n",
    "    # Define the output file path with the same name as the input audio file\n",
    "    output_file_path = os.path.join(output_folder, f\"{file_name_without_extension}.txt\")\n",
    "\n",
    "    # Write to a text file\n",
    "    with open(output_file_path, \"w\", encoding=\"utf-8\") as output_file:\n",
    "        output_file.write(output_text_str)\n",
    "\n",
    "    print(f\"Transcription saved to {output_file_path}\")\n",
    "\n",
    "# Replace with your GCS audio file URI, credentials path, and desired output folder\n",
    "audio_file_uri = \"gs://nigeria-3/1217.MP3\"  # Your GCS URI\n",
    "credentials_path = \"C:/gcloud/service-account-key.json\"  # Change to your credentials file path\n",
    "output_folder = \"output\"  # Specify the output folder\n",
    "\n",
    "# Call the function\n",
    "transcribe_audio_with_diarization(audio_file_uri, credentials_path, output_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from google.cloud import speech_v1p1beta1 as speech\n",
    "import time\n",
    "\n",
    "def transcribe_audio_with_diarization_async(audio_file_path, credentials_path, output_folder):\n",
    "    # Set Google Cloud credentials\n",
    "    os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = credentials_path\n",
    "\n",
    "    # Initialize the client\n",
    "    client = speech.SpeechClient()\n",
    "\n",
    "    # Read the audio file\n",
    "    with open(audio_file_path, \"rb\") as audio_file:\n",
    "        content = audio_file.read()\n",
    "\n",
    "    # Configure recognition request\n",
    "    audio = speech.RecognitionAudio(content=content)\n",
    "    config = speech.RecognitionConfig(\n",
    "        encoding=speech.RecognitionConfig.AudioEncoding.LINEAR16,  # Encoding for .m4a files\n",
    "        sample_rate_hertz=44100,  # Sample rate for your audio file\n",
    "        language_code=\"en-US\",\n",
    "        enable_automatic_punctuation=True,\n",
    "        enable_speaker_diarization=True,\n",
    "        diarization_speaker_count=2,  # Specify the number of speakers\n",
    "        model=\"telephone\"  # Adjust based on the use case, e.g., \"phone_call\"\n",
    "    )\n",
    "\n",
    "    # Perform asynchronous recognition\n",
    "    operation = client.long_running_recognize(config=config, audio=audio)\n",
    "\n",
    "    print(\"Processing audio...\")\n",
    "\n",
    "    # Wait for the operation to complete\n",
    "    response = operation.result(timeout=600)  # Timeout after 10 minutes (adjust if needed)\n",
    "\n",
    "    # Group words by speakers\n",
    "    speaker_transcripts = {}\n",
    "    for result in response.results:\n",
    "        for word_info in result.alternatives[0].words:\n",
    "            speaker = word_info.speaker_tag\n",
    "            word = word_info.word\n",
    "            if speaker not in speaker_transcripts:\n",
    "                speaker_transcripts[speaker] = []\n",
    "            speaker_transcripts[speaker].append(word)\n",
    "\n",
    "    # Prepare output text\n",
    "    output_text = []\n",
    "    for speaker, words in speaker_transcripts.items():\n",
    "        output_text.append(f\"Speaker {speaker}: {' '.join(words)}\")\n",
    "\n",
    "    # Join the text with line breaks\n",
    "    output_text_str = \"\\n\\n\".join(output_text)\n",
    "\n",
    "    # Ensure the output folder exists\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    # Get the base name of the input audio file without extension\n",
    "    file_name_without_extension = os.path.splitext(os.path.basename(audio_file_path))[0]\n",
    "\n",
    "    # Define the output file path with the same name as the input audio file\n",
    "    output_file_path = os.path.join(output_folder, f\"{file_name_without_extension}.txt\")\n",
    "\n",
    "    # Write to a text file\n",
    "    with open(output_file_path, \"w\", encoding=\"utf-8\") as output_file:\n",
    "        output_file.write(output_text_str)\n",
    "\n",
    "    print(f\"Transcription saved to {output_file_path}\")\n",
    "\n",
    "\n",
    "# Replace with your audio file path, credentials path, and desired output folder\n",
    "audio_file_path = \"dataset/Nigeria/CBM HEAD.m4a\"  # Change to your .m4a file path\n",
    "credentials_path = \"C:/gcloud/service-account-key.json\"  # Change to your credentials file path\n",
    "output_folder = \"output\"  # Specify the output folder\n",
    "\n",
    "# Call the function\n",
    "transcribe_audio_with_diarization_async(audio_file_path, credentials_path, output_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for operation to complete...\n",
      "Transcript: so uh just chat with could you please um Talk a bit more about CBM Nigeria what it is doing when it has started operating in Nigeria and our activities and our view of activities\n",
      "Transcript:  okay um my name is\n"
     ]
    }
   ],
   "source": [
    "from google.cloud import speech\n",
    "\n",
    "# Path to the local audio file\n",
    "local_file_path = \"dataset/1215.MP3\"\n",
    "\n",
    "def transcribe_speech():\n",
    "    # Instantiates a client\n",
    "    client = speech.SpeechClient()\n",
    "\n",
    "    # Read the audio file into memory\n",
    "    with open(local_file_path, \"rb\") as audio_file:\n",
    "        content = audio_file.read()\n",
    "\n",
    "    # Set up the recognition configuration\n",
    "    config = speech.RecognitionConfig(\n",
    "        encoding=speech.RecognitionConfig.AudioEncoding.MP3,\n",
    "        sample_rate_hertz=44100,\n",
    "        language_code=\"en-US\",\n",
    "        model=\"telephony\",\n",
    "        audio_channel_count=2,\n",
    "    )\n",
    "\n",
    "    # Create the RecognitionAudio object with the local content\n",
    "    audio = speech.RecognitionAudio(content=content)\n",
    "\n",
    "    # Detects speech in the audio file\n",
    "    operation = client.long_running_recognize(config=config, audio=audio)\n",
    "\n",
    "    print(\"Waiting for operation to complete...\")\n",
    "    response = operation.result(timeout=90)\n",
    "\n",
    "    for result in response.results:\n",
    "        print(\"Transcript: {}\".format(result.alternatives[0].transcript))\n",
    "\n",
    "# Call the function\n",
    "transcribe_speech()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
